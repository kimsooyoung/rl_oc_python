{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319d5c23-2d3e-4180-a77a-97dde0d0d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic DQN with gym cartpole model\n",
    "# referenced from : https://github.com/seungeunrho/RLfrombasics/blob/master/ch8_DQN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca09a2b-431f-4b9b-b350-af5c2876bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory checking required\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c15538-6766-4407-bb8c-ca307d4819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a47a35-b9bd-47f9-ab77-5e511cd598d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import renderlab as rl\n",
    "import numpy as np\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88530b4-da5c-445f-a301-11baed3b6af8",
   "metadata": {},
   "source": [
    "## Env Rendering Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ac4eea-88c2-4672-a756-f4c497e30aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  14.0\n",
      "Moviepy - Building video temp-{start}.mp4.\n",
      "Moviepy - Writing video temp-{start}.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready temp-{start}.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode = \"rgb_array\")\n",
    "env = rl.RenderFrame(env, \"./output\")\n",
    "\n",
    "observation, info = env.reset()\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    score += reward\n",
    "    \n",
    "    if terminated:\n",
    "        print(\"Score : \", score)\n",
    "        break\n",
    "\n",
    "# Below playing requires high memory usage, which can result in torch import error\n",
    "env.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e1c6a-06fb-4194-bcc3-b0b02a1098ab",
   "metadata": {},
   "source": [
    "## Assign Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b721d6-5cfb-4346-8ba1-d5cf7873e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32\n",
    "target_update_interval = 20\n",
    "print_interval = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c08aa5-9907-4450-8a71-cf95b2390fc8",
   "metadata": {},
   "source": [
    "## Define ReplayBuffer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7e015f-fbe5-41f6-bf05-b72256ed69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    \n",
    "    def __init__(self, buffer_limit=50000):\n",
    "        self._buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self._buffer.append(transition)\n",
    "\n",
    "    def sample_test(self, n):\n",
    "        batch = random.sample(self._buffer, n)\n",
    "        s_list, a_list, r_list, sp_list, done_list = [], [], [], [], []\n",
    "\n",
    "        for transition in batch:\n",
    "            s, a, r, sp, done = transition\n",
    "            print(transition)\n",
    "            break\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def sample(self, n):\n",
    "        batch = random.sample(self._buffer, n)\n",
    "        s_list, a_list, r_list, sp_list, done_list = [], [], [], [], []\n",
    "\n",
    "        for transition in batch:\n",
    "            s, a, r, sp, done = transition\n",
    "            s_list.append(s)\n",
    "            a_list.append([a])\n",
    "            r_list.append([r])\n",
    "            sp_list.append(sp)\n",
    "            done_list.append(done)\n",
    "\n",
    "        return torch.tensor(s_list, dtype=torch.float), \\\n",
    "                torch.tensor(a_list), torch.tensor(r_list), \\\n",
    "                torch.tensor(sp_list, dtype=torch.float), \\\n",
    "                torch.tensor(done_list)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self._buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80eef3-5012-4647-8f6f-5eaa1a579aa3",
   "metadata": {},
   "source": [
    "## Qnet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fca39b-c8dc-42b8-97d0-49da3bf28b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.fc1(x))\n",
    "        x2 = F.relu(self.fc2(x1))\n",
    "        return self.fc3(x2)\n",
    "\n",
    "    def sample_action(self, obs, eps):\n",
    "        coin = random.random()\n",
    "        if coin < eps:\n",
    "            return random.randint(0, 1)\n",
    "        else:\n",
    "            out = self.forward(obs)\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d6312-9cae-4a48-a712-658ec3418db6",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f691e40d-b7d6-42b6-b5bb-1fe2eae19c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, q, q_target, buffer, optimizer):\n",
    "    for i in range(train_iter):\n",
    "        s_list, a_list, r_list, sp_list, done_list = buffer.sample(batch_size)\n",
    "\n",
    "        target_value = r_list + gamma * q_target(sp_list).max(1)[0].unsqueeze(1) * done_list\n",
    "        action_value = q(s_list).gather(1, a_list)\n",
    "\n",
    "        loss = F.smooth_l1_loss(action_value, target_value)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8103028f-f47a-4b5a-96ac-fcc22d72fb46",
   "metadata": {},
   "source": [
    "- PyTorch Gather Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e9bc38-ff9e-4fd7-baec-c6cb38cbf5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube = torch.tensor(np.array([1,2,3,4,5,6]))\n",
    "selection = torch.tensor(random.randint(0, 5))\n",
    "out = cube.gather(0, selection)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d9a2f-2805-43a6-8b54-508b350f1d38",
   "metadata": {},
   "source": [
    "# Main Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d24c742-ed77-4de6-9977-8d822d78c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "q = Qnet()\n",
    "q_target = Qnet()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "optimizer = optim.Adam(q.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86326c13-f8e1-4564-858e-9b10173518c6",
   "metadata": {},
   "source": [
    "## Main Loop for Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f50297-58ce-4b25-8fa5-d7d135ff6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :1000, score : 8.0, n_buffer : 50000, eps : 3.0%\n",
      "n_episode :2000, score : 10.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3000, score : 9.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4000, score : 9.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :5000, score : 11.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :6000, score : 9.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :7000, score : 10.0, n_buffer : 50000, eps : 1.0%\n"
     ]
    }
   ],
   "source": [
    "for n_epi in range(10000):\n",
    "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "    s, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0.0\n",
    "\n",
    "    while not done:\n",
    "        a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n",
    "        s_prime, r, done, truncated, info = env.step(a)\n",
    "        done_mask = 0.0 if done else 1.0\n",
    "        \n",
    "        memory.put((s, a, r/100.0, s_prime, done_mask))\n",
    "        # action and reward are plain scalars\n",
    "        # memory.sample_test(1)\n",
    "        # break\n",
    "        \n",
    "        s = s_prime\n",
    "        score += r\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    if memory.size() > 2000:\n",
    "        train(10, q, q_target, memory, optimizer)\n",
    "\n",
    "    if n_epi % target_update_interval == 0:\n",
    "        q_target.load_state_dict(q.state_dict())\n",
    "\n",
    "    if n_epi % print_interval == 0 and n_epi != 0:\n",
    "        print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score, memory.size(), epsilon*100))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068e59c-df3b-4ffa-9099-67c5dd484b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
